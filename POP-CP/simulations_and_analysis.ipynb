{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import popcp\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dir(popcp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations on Gaussian Data (ยง 4.1-4.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of sample size on estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced samples\n",
    "# Sample size ranges from 20 to 2000, step size = 20\n",
    "# Gaussian distributions, identity covariance, equal displacement in all directions\n",
    "\n",
    "sims_SS = {}\n",
    "dims = [2, 8, 32, 128]\n",
    "estimators = ['naive', 'halfnhalf', 'unregularized_pooled', 'regularized_pooled']\n",
    "\n",
    "for estimator in estimators:\n",
    "    for dim in dims:\n",
    "        distance_scaling = (2/dim)**(1/2)\n",
    "        displacement = 0.2*distance_scaling\n",
    "        mu1 = np.zeros(dim)\n",
    "        mu2 = mu1 + displacement\n",
    "        cov1 = np.identity(dim)\n",
    "        cov2 = np.identity(dim)\n",
    "        \n",
    "        sims_SS[(estimator, str(dim)+'D')] = []\n",
    "        \n",
    "        for sample_size in range(20,2000,20):\n",
    "            N1 = sample_size//2\n",
    "            N2 = sample_size//2\n",
    "\n",
    "            true_CP = popcp.gaussian_ND_true_CP(mu1, mu2, cov1, cov2)\n",
    "            estimate, var = popcp.monte_carlo_CP(mu1, mu2, cov1, cov2, estimator, N1, N2, M)\n",
    "            sims_SS[(estimator, str(dim)+'D')].append([sample_size, estimate - true_CP, var])\n",
    "        \n",
    "        sims_SS[(estimator, str(dim)+'D')] = np.array(sims_SS[(estimator, str(dim)+'D')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/amyf')\n",
    "with open('sims_SS.pickle', 'wb') as handle:\n",
    "    pickle.dump(sims_SS, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of true CP on estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 10000\n",
    "# distances in 2D that give equally spaced grid of true CPs\n",
    "trueCPs_grid_2D = np.load('/home/amyf/trueCPs_grid_2D.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced samples\n",
    "# True CP increases from 0.5 to 1, step size = 0.005\n",
    "# Gaussian distributions, identity covariance, equal displacement in all directions\n",
    "\n",
    "sims_tCP = {}\n",
    "dims = [2, 8, 32, 128]\n",
    "sample_sizes = [20, 200, 2000]\n",
    "estimators = ['naive', 'halfnhalf', 'unregularized_pooled', 'regularized_pooled']\n",
    "\n",
    "for estimator in estimators:\n",
    "    for dim in dims:\n",
    "        distance_scaling = (2/dim)**(1/2)\n",
    "        mu1 = np.zeros(dim)\n",
    "        cov1 = np.identity(dim)\n",
    "        cov2 = np.identity(dim)\n",
    "\n",
    "        for sample_size in sample_sizes:\n",
    "            N1 = sample_size//2\n",
    "            N2 = sample_size//2\n",
    "            \n",
    "            sims_tCP[(estimator, str(dim)+'D', sample_size)] = []\n",
    "            \n",
    "            for dist in trueCPs_grid_2D*distance_scaling:\n",
    "                mu2 = mu1 + dist\n",
    "\n",
    "                true_CP = popcp.gaussian_ND_true_CP(mu1, mu2, cov1, cov2)\n",
    "                estimate, var = popcp.monte_carlo_CP(mu1, mu2, cov1, cov2, estimator, N1, N2, M)\n",
    "                sims_tCP[(estimator, str(dim)+'D', sample_size)].append([true_CP, estimate - true_CP, var])\n",
    "                \n",
    "            sims_tCP[(estimator, str(dim)+'D', sample_size)] = np.array(sims_tCP[(estimator, str(dim)+'D', sample_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/amyf')\n",
    "with open('sims_tCP.pickle', 'wb') as handle:\n",
    "    pickle.dump(sims_tCP, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Bias Correction (ยง 4.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/amyf/pickles/sims_tCP.pickle', 'rb') as handle:\n",
    "    sims_tCP = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_points_delta_method(points, smoothness):\n",
    "    \"\"\"\n",
    "    Performs delta method on all points given.\n",
    "    \n",
    "    Parameters:\n",
    "        points (ndarray): column 1 - estimated CPs, column 2 - true CPs, \n",
    "                        column 3 - variance in estimated CP (each point is stored in one row)\n",
    "        smoothness (scalar): smoothness of spline interpolation\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    points = points[points[:,0].argsort()]\n",
    "    \n",
    "    f = popcp.interpolate.splrep(points[:,0], points[:,1], k=5, s=smoothness)\n",
    "    fprime = popcp.interpolate.splder(f)\n",
    "    \n",
    "    deriv = popcp.interpolate.splev(points[:,0], fprime)\n",
    "    real_var = points[:,2] * (deriv**2) \n",
    "    return real_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [2, 8, 32, 128]\n",
    "sample_sizes = [20, 200, 2000]\n",
    "true_CPs = np.array([0.5,0.6,0.7,0.8,0.9,1.0])\n",
    "synthetic_bc = {}\n",
    "\n",
    "for dim in dims:\n",
    "    distance_scaling = (2/dim)**(1/2)\n",
    "    \n",
    "    for sample_size in sample_sizes:\n",
    "        N1 = sample_size//2\n",
    "        N2 = sample_size //2\n",
    "\n",
    "        points = sims_tCP['regularized_pooled', str(dim)+'D', sample_size]\n",
    "        # swap bias and true CP columns so bias is first\n",
    "        points[:,[0,1]] = points[:,[1,0]]\n",
    "        # recover estimated CP from bias\n",
    "        points[:,0] = points[:,0] + points[:,1]\n",
    "        SDs = np.sqrt(all_points_delta_method(points, 0.001))\n",
    "        # delta method done for all points in grid, interpolate to get values for intermediate points\n",
    "        f_upper = interp1d(points[:,0], points[:,1] + 2*SDs, fill_value='extrapolate')\n",
    "        f_middle = interp1d(points[:,0], points[:,1], fill_value='extrapolate')\n",
    "        f_lower = interp1d(points[:,0], points[:,1] - 2*SDs, fill_value='extrapolate')\n",
    "        \n",
    "        dists = np.array(trueCPs_grid_2D[[0,20,40,60,80,100]]) * distance_scaling\n",
    "        \n",
    "        synthetic_bc[(str(dim)+'D', sample_size)] = []\n",
    "\n",
    "        for dist, true_CP in zip(dists, true_CPs):\n",
    "            for i in range(5):\n",
    "                #simulate to get an estimated CP\n",
    "                x1 = np.random.multivariate_normal(np.zeros(dim), np.identity(dim), N1)\n",
    "                x2 = np.random.multivariate_normal(np.zeros(dim) + dist, np.identity(dim), N2)\n",
    "                e_CP = popcp.regularized_pooled_estimator(x1, x2)\n",
    "\n",
    "                # get confidence interval\n",
    "                CI_upper = f_upper(e_CP).tolist()\n",
    "                CI_middle = f_middle(e_CP).tolist()\n",
    "                CI_lower = f_lower(e_CP).tolist()\n",
    "                synthetic_bc[(str(dim)+'D', sample_size)].append([true_CP, e_CP, CI_middle, CI_lower, CI_upper])\n",
    "        \n",
    "        synthetic_bc[(str(dim)+'D', sample_size)] = np.array(synthetic_bc[(str(dim)+'D', sample_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/amyf')\n",
    "with open('synthetic_bc.pickle', 'wb') as handle:\n",
    "    pickle.dump(synthetic_bc, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Data from Zhao et. al (ยง 5.1-5.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frozen trials data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frozen_data = pd.read_csv('/home/amyf/real data/Frozen data/frozen_trials.csv')\n",
    "frozen_zeros = frozen_data.loc[frozen_data['choice'] == 1]\n",
    "frozen_zeros = frozen_zeros.sample(frac=1).reset_index(drop=True)\n",
    "frozen_ones = frozen_data.loc[frozen_data['choice'] == 2]\n",
    "frozen_ones = frozen_ones.sample(frac=1).reset_index(drop=True)\n",
    "frozen_data = frozen_zeros.append(frozen_ones, ignore_index=True)\n",
    "\n",
    "print(frozen_data['choice'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_ind_CPs = []\n",
    "for i in range(27):\n",
    "    CP = popcp.choice_prob_1D(frozen_data.iloc[:, i], frozen_data['choice'])\n",
    "    if (CP < 0.5):\n",
    "        CP = 1 - CP\n",
    "    frozen_ind_CPs.append([i + 1, CP])\n",
    "    \n",
    "frozen_ind_CPs.sort(key=lambda x:1-x[1])\n",
    "frozen_ind_CPs = np.array(frozen_ind_CPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_subset_CP(data, neurons, N1, N2):\n",
    "    \"\"\"\n",
    "    Calculates CP for a subset of neurons.\n",
    "    \n",
    "    Paramters:\n",
    "        data (dataframe): trials with neuron recordings\n",
    "        neurons (list or ndarray): neurons to be used\n",
    "        N1 (int): number of positive trials\n",
    "        N2 (int): number of negative trials\n",
    "    \"\"\"\n",
    "    \n",
    "    data_used = np.array(data.iloc[:, [neuron - 1 for neuron in neurons]])\n",
    "    positive_trials = data_used[:N1, :]\n",
    "    negative_trials = data_used[-N2:, :]\n",
    "    \n",
    "    return popcp.estimate_CP(negative_trials, positive_trials, 'regularized_pooled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "neurons_2D_random = []\n",
    "for i in range(5):\n",
    "    neurons = random.sample(range(1, 28), 2)\n",
    "    neurons_2D_random.append(neurons)\n",
    "    \n",
    "neurons_2D_best = []\n",
    "for i in range(0, 10, 2):\n",
    "    neurons_2D_best.append([int(n) for n in frozen_ind_CPs[i:i+2, 0].tolist()])\n",
    "\n",
    "neurons_8D_random = []\n",
    "for i in range(5):\n",
    "    neurons = random.sample(range(1, 28), 8)\n",
    "    neurons_8D_random.append(neurons)\n",
    "    \n",
    "neurons_8D_best = []\n",
    "for i in range(5):\n",
    "    neurons = random.sample(range(1, 14), 8)\n",
    "    neurons_8D_best.append(neurons)\n",
    "\n",
    "all_neurons = [np.arange(1,28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_neurons = [np.arange(1,28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_trials_analysis = {}\n",
    "N1 = 43\n",
    "N2 = 43\n",
    "\n",
    "groups = [(2, '2D_random', neurons_2D_random), (2, '2D_best', neurons_2D_best), (8, '8D_random', neurons_8D_random), (8, '8D_best', neurons_8D_best), (27, 'all', all_neurons)]\n",
    "\n",
    "for group in groups:\n",
    "    dim = group[0]\n",
    "    cov1 = np.identity(dim)\n",
    "    cov2 = np.identity(dim)\n",
    "    \n",
    "    frozen_trials_analysis[(group[0],group[1])] = []\n",
    "    \n",
    "    for subset in group[2]:\n",
    "        eCP = neuron_subset_CP(frozen_data, subset, N1, N2)\n",
    "        CI = popcp.estimate_CI(eCP, 'regularized_pooled', N1, N2, dim, cov1, cov2, 2, 1)\n",
    "        frozen_trials_analysis[(group[0],group[1])].append(CI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in all_neurons:\n",
    "    eCP = neuron_subset_CP(frozen_data, subset, N1, N2)\n",
    "    CI = popcp.estimate_CI(eCP, 'regularized_pooled', N1, N2, dim, cov1, cov2, 2, 1)\n",
    "    frozen_trials_analysis[27, 'all'].append(CI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in frozen_trials_analysis.items():\n",
    "    frozen_trials_analysis[key] = np.asarray(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/amyf')\n",
    "with open('frozen_trials_analysis.pickle', 'wb') as handle:\n",
    "    pickle.dump(frozen_trials_analysis, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weak trials data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_data = pd.read_csv('/home/amyf/real data/Weak data/weak_trials.csv')\n",
    "weak_data.columns=['N1','N2','N3','N4','N5','N6','N7','N8','N9','N10','N11','N12','N13','N14','N15','N16','N17','N18','N19','N20','N21','N22','N23','N24','N25','N26','N27','choice']\n",
    "weak_zeros = weak_data.loc[weak_data['choice'] == 0]\n",
    "weak_zeros = weak_zeros.sample(frac=1).reset_index(drop=True)\n",
    "weak_ones = weak_data.loc[weak_data['choice'] == 1]\n",
    "weak_ones = weak_ones.sample(frac=1).reset_index(drop=True)\n",
    "weak_data = weak_zeros.append(weak_ones, ignore_index=True)\n",
    "\n",
    "print(weak_data['choice'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_ind_CPs = []\n",
    "for i in range(27):\n",
    "    CP = popcp.choice_prob_1D(weak_data.iloc[:, i], weak_data['choice'])\n",
    "    if (CP < 0.5):\n",
    "        CP = 1 - CP\n",
    "    weak_ind_CPs.append([i + 1, CP])\n",
    "    \n",
    "weak_ind_CPs.sort(key=lambda x:1-x[1])\n",
    "weak_ind_CPs = np.array(weak_ind_CPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "neurons_2D_random = []\n",
    "for i in range(5):\n",
    "    neurons = random.sample(range(1, 28), 2)\n",
    "    neurons_2D_random.append(neurons)\n",
    "    \n",
    "neurons_2D_best = []\n",
    "for i in range(0, 10, 2):\n",
    "    neurons_2D_best.append([int(n) for n in weak_ind_CPs[i:i+2, 0].tolist()])\n",
    "\n",
    "neurons_8D_random = []\n",
    "for i in range(5):\n",
    "    neurons = random.sample(range(1, 28), 8)\n",
    "    neurons_8D_random.append(neurons)\n",
    "    \n",
    "neurons_8D_best = []\n",
    "for i in range(5):\n",
    "    neurons = random.sample(range(1, 14), 8)\n",
    "    neurons_8D_best.append(neurons)\n",
    "\n",
    "all_neurons = [np.arange(1,28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weak_trials_analysis = {}\n",
    "N1 = 236\n",
    "N2 = 236\n",
    "\n",
    "groups = [(2, '2D_random', neurons_2D_random), (2, '2D_best', neurons_2D_best), (8, '8D_random', neurons_8D_random), (8, '8D_best', neurons_8D_best), (27, 'all', all_neurons)]\n",
    "\n",
    "for group in groups:\n",
    "    dim = group[0]\n",
    "    cov1 = np.identity(dim)\n",
    "    cov2 = np.identity(dim)\n",
    "    \n",
    "    weak_trials_analysis[(group[0],group[1])] = []\n",
    "    \n",
    "    for subset in group[2]:\n",
    "        eCP = neuron_subset_CP(weak_data, subset, N1, N2)\n",
    "    \n",
    "        CI = popcp.estimate_CI(eCP, 'regularized_pooled', N1, N2, dim, cov1, cov2, 2, 1)\n",
    "        weak_trials_analysis[(group[0],group[1])].append(CI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in weak_trials_analysis.items():\n",
    "    weak_trials_analysis[key] = np.asarray(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/amyf')\n",
    "with open('weak_trials_analysis.pickle', 'wb') as handle:\n",
    "    pickle.dump(weak_trials_analysis, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsampling weak trials data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_data_copy = weak_data.copy()\n",
    "weak_zeros_copy = weak_data_copy.loc[weak_data_copy['choice'] == 0]\n",
    "weak_ones_copy = weak_data_copy.loc[weak_data_copy['choice'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_trials_sanity_check = {}\n",
    "all_neurons = np.arange(1,28)\n",
    "sample_sizes = [86, 200, 300, 400, 472]\n",
    "dim = 27\n",
    "cov1 = np.identity(dim)\n",
    "cov2 = np.identity(dim)\n",
    "\n",
    "for sample_size in sample_sizes:\n",
    "    N1 = sample_size//2\n",
    "    N2 = sample_size//2\n",
    "    \n",
    "    weak_trials_sanity_check[sample_size] = []\n",
    "    \n",
    "    for seed in range(25):\n",
    "        weak_zeros_copy = weak_zeros_copy.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "        weak_ones_copy = weak_ones_copy.sample(frac=1, random_state=seed+25).reset_index(drop=True)\n",
    "        weak_data_copy = weak_zeros_copy.append(weak_ones_copy, ignore_index=True)\n",
    "        eCP = neuron_subset_CP(weak_data_copy, all_neurons, N1, N2)\n",
    "        CI = popcp.estimate_CI(eCP, 'regularized_pooled', N1, N2, dim, cov1, cov2, 2, 1)\n",
    "        \n",
    "        weak_trials_sanity_check[sample_size].append(CI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in weak_trials_sanity_check.items():\n",
    "    weak_trials_sanity_check[key] = np.asarray(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/amyf')\n",
    "with open('weak_trials_sanity_check.pickle', 'wb') as handle:\n",
    "    pickle.dump(weak_trials_sanity_check, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
